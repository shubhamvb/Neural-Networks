from csv import reader
from random import shuffle

def load_csv_file(filename):
	dataset = list()
	with open(filename, 'r') as f:
		file_reader = reader(f)
		for row in file_reader:
			if not row:
				continue
			dataset.append(row)
	return dataset

def activation_function(input):
	threshold = 0
	if input >= threshold :
		return 1
	elif input < threshold : 	
		return 0
	

def calc_net_input(data, weights, bias):
	netInput = 0
	for i in range(len(data)-1) :
		netInput += data[i] * weights[i]
	netInput += bias
	return netInput

def update_weights(data, weights, learning_rate, error):
	for i in range(len(weights)) :
		weights[i] += (learning_rate * error * data[i])
	return weights

def update_bias(bias, target_output, learning_rate):
	bias  += (learning_rate * target_output)
	return bias

def train_perceptron_model(dataset, learning_rate, weights, bias):
	target_output_col = len(dataset[0]) - 1
	for i in range(len(dataset)):
			input = calc_net_input(dataset[i], weights, bias)
			actual_output = activation_function(input)
			target_output = dataset[i][target_output_col]
			weights = update_weights(dataset[i], weights, learning_rate, target_output-actual_output)
			bias = update_bias(bias, target_output-actual_output, learning_rate)
	
	return weights, bias

def evaluate_perceptron_model(dataset, learning_rate, weights, bias):
	target_output_col = len(dataset[0]) - 1
	match = 0
	for i in range(len(dataset)):
		input = calc_net_input(dataset[i], weights, bias)
		actual_output = activation_function(input)
		target_output = dataset[i][target_output_col]
		if target_output == actual_output:
			match += 1;
			
	return match*100/len(dataset)

def convert_str_to_float(dataset, col):
	for row in dataset:
		row[col] = float(row[col].strip())

def convert_str_to_int(dataset, col):
	labels = [row[col] for row in dataset]
	unique_labels = set(labels)
	hashmap = dict()
	for i,label in enumerate(unique_labels):
		hashmap[label] = i
	for row in dataset:
		row[col] = hashmap[row[col]]

'''loading data from csv '''
filename = "sonar.all-data.csv"
dataset = load_csv_file(filename)

for col in range(len(dataset[0])-1):
	convert_str_to_float(dataset, col)

convert_str_to_int(dataset, len(dataset[0])-1)

'''Creating the training and test dataset '''
shuffle(dataset)
training_set_length = int(len(dataset) * 0.7)
train_set = dataset[:training_set_length]
test_set = dataset[training_set_length :]


epochs = 100
learning_rate = 0.1
weights = [0.1 for i in range(len( dataset[0])-1)]
bias = 0.0
for i in range(epochs) :
	weights, bias = train_perceptron_model( train_set, learning_rate, weights, bias )
	
	
match = evaluate_perceptron_model( test_set, learning_rate, weights, bias )
print("Prediction Accuracy :- ",match)

